# ğŸ¤– Reolink AI - Cron Job Setup

## ğŸ“ Skript-Ãœbersicht

### 1ï¸âƒ£ `run_person.sh` - Person Detection
FÃ¼hrt **person.py** mit GPU-UnterstÃ¼tzung aus:
- âœ… Erkennt Gesichter in Bildern/Videos
- âœ… Speichert Face Embeddings (ArcFace, 512-dim)
- âœ… Erkennt Personen mit YOLO
- âœ… Schreibt alles in die Datenbank

**Parameter:**
```bash
./run_person.sh                    # Standard (nur JPG, Debug)
./run_person.sh --limit 100        # Max 100 Dateien
./run_person.sh --force            # Alles neu analysieren
./run_person.sh --debug --limit 10 # Test-Modus
```

---

### 2ï¸âƒ£ `run_cluster.sh` - Face Clustering
FÃ¼hrt **cam2_cluster_faces.py** aus:
- âœ… Gruppiert identische Gesichter
- âœ… Verwendet DBSCAN Clustering
- âœ… Basiert auf Cosine Distance der Face Embeddings
- âœ… Schreibt `face_cluster_id` in die DB

**Aufruf:**
```bash
./run_cluster.sh
```

---

### 3ï¸âƒ£ `run_chain.sh` - Komplette Verarbeitungskette â­ **EMPFOHLEN**
FÃ¼hrt beide Schritte nacheinander aus:
1. Person Detection
2. Face Clustering (nur wenn Step 1 erfolgreich)

**Parameter:**
```bash
./run_chain.sh                 # Volle Verarbeitung
./run_chain.sh --limit 500     # Max 500 Dateien
```

---

## âš™ï¸ Installation (Crontab)

### Schritt 1: Pfade anpassen
Bearbeite `crontab.example` und ersetze `/home/gh/python` mit deinem Pfad:
```bash
nano crontab.example
```

### Schritt 2: Crontab installieren
```bash
crontab -e
```

FÃ¼ge eine der folgenden Zeilen ein:

#### Option A: TÃ¤glich um 2:00 Uhr (Produktiv)
```cron
0 2 * * * /home/gh/python/reolink_AI/run_chain.sh
```

#### Option B: Alle 6 Stunden (mit Limit)
```cron
0 */6 * * * /home/gh/python/reolink_AI/run_chain.sh --limit 1000
```

#### Option C: StÃ¼ndlich (kleine Batches)
```cron
0 * * * * /home/gh/python/reolink_AI/run_chain.sh --limit 100
```

### Schritt 3: Crontab Ã¼berprÃ¼fen
```bash
crontab -l
```

---

## ğŸ“Š Logs

Alle Logs werden automatisch erstellt in:
```
reolink_AI/logs/
â”œâ”€â”€ person.log          # Person Detection (aktuell)
â”œâ”€â”€ person.log.old      # Person Detection (vorheriger Lauf)
â”œâ”€â”€ cluster.log         # Face Clustering (aktuell)
â”œâ”€â”€ cluster.log.old     # Face Clustering (vorheriger Lauf)
â”œâ”€â”€ chain.log           # Komplette Chain (aktuell)
â””â”€â”€ chain.log.old       # Komplette Chain (vorheriger Lauf)
```

**Logs werden ÃœBERSCHRIEBEN** - kein MÃ¼llhaufen mit tausend Log-Dateien!
Das vorherige Log wird als `.old` Backup behalten.

**Logs anschauen:**
```bash
# Aktuelles Chain-Log
cat logs/chain.log

# Vorheriges Chain-Log
cat logs/chain.log.old

# Live-Ansicht (tail -f)
tail -f logs/chain.log

# Nur Fehler anzeigen
grep -i error logs/chain.log
```

---

## ğŸ§ª Test vor Produktiv-Betrieb

**Manueller Test:**
```bash
cd ~/python/reolink_AI

# Test mit 10 Dateien
./run_chain.sh --limit 10

# PrÃ¼fe Logs
cat logs/chain_*.log | tail -50
```

**Erwartetes Ergebnis:**
```
âœ… Person Detection erfolgreich
âœ… Face Clustering erfolgreich
Gesamt-Dauer: 2m 15s
```

---

## ğŸ”§ Troubleshooting

### Problem: "CUDA not available"
**LÃ¶sung:** PrÃ¼fe CUDA-Installation:
```bash
nvidia-smi
/usr/local/cuda-11.8/bin/nvcc --version
```

### Problem: "Permission denied"
**LÃ¶sung:** Skripte ausfÃ¼hrbar machen:
```bash
chmod +x run_*.sh
```

### Problem: "ModuleNotFoundError"
**LÃ¶sung:** Virtual Environment aktivieren:
```bash
source /home/gh/python/venv_py311/bin/activate
pip install -r requirements.txt
```

### Problem: Keine neuen Gesichter erkannt
**PrÃ¼fe:**
1. Sind neue Dateien vorhanden?
   ```bash
   ls -lt /var/www/web1/files/ | head
   ```
2. Sind sie bereits in der DB?
   ```sql
   SELECT COUNT(*) FROM cam2_recordings WHERE DATE(recorded_at) = CURDATE();
   ```
3. Force Re-Processing:
   ```bash
   ./run_person.sh --force --limit 50
   ```

---

## ğŸ“ˆ Performance

| Modus | Dateien/Min | GPU-Auslastung | CPU-Last |
|-------|-------------|----------------|----------|
| JPG-Only | ~600 | 30-50% | Niedrig |
| JPG+MP4 | ~120 | 80-100% | Mittel |
| Force Re-Scan | ~80 | 90-100% | Hoch |

**Empfehlung fÃ¼r Produktiv:**
- StÃ¼ndlich: `--limit 100` (schnell, kontinuierlich)
- NÃ¤chtlich: Keine Limits (vollstÃ¤ndig)

---

## ğŸ¯ Best Practices

1. âœ… **Teste erst mit `--limit 10`** bevor du Produktiv gehst
2. âœ… **Verwende `run_chain.sh`** statt separate Skripte
3. âœ… **Log-Rotation einrichten** (verhindert volle Festplatte)
4. âœ… **Monitoring einrichten** (z.B. mit `monit` oder `systemd-timer`)
5. âœ… **Backup der Datenbank** vor groÃŸen Re-Processing-LÃ¤ufen

---

## ğŸ“ Beispiel-Workflow (Produktiv)

```cron
# TÃ¤glich um 2:00 Uhr: Volle Verarbeitung
0 2 * * * /home/gh/python/reolink_AI/run_chain.sh

# StÃ¼ndlich: Neue Dateien (max 200)
0 * * * * /home/gh/python/reolink_AI/run_chain.sh --limit 200
```

**Status prÃ¼fen:**
```bash
# Heute verarbeitete Dateien
mysql -u gh -pa12345 wagodb -e "SELECT COUNT(*) FROM cam2_recordings WHERE DATE(recorded_at) = CURDATE();"

# Heute erkannte Gesichter
mysql -u gh -pa12345 wagodb -e "SELECT COUNT(*) FROM cam2_detected_faces WHERE DATE(detected_at) = CURDATE();"

# Cluster-Statistik
./run_cluster.sh
```

---

**Viel Erfolg! ğŸš€**
